{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_H-LGChalxcK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "datasets_dir = os.getcwd() + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions_2016 = 'contributions-2015-2016.csv'\n",
    "df_contributions_2016 = pd.read_csv(datasets_dir + contributions_2016, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "statereps_2016 = 'State_Reps_2015-2016.csv'\n",
    "df_reps_2016 = pd.read_csv(datasets_dir + statereps_2016, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "NfPq8mbWlxcR",
    "outputId": "50538f67-f689-4a71-82dd-f2eac3c458f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "contributions_2018 = 'contributions-2017-2018.csv'\n",
    "df_contributions_2018 = pd.read_csv(datasets_dir + contributions_2018, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "statereps_2018 = 'State_Reps_2017-2018.csv'\n",
    "df_reps_2018 = pd.read_csv(datasets_dir + statereps_2018, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_companies = 'real_estate_companies.txt'\n",
    "df_real_estate = pd.read_csv(datasets_dir + real_estate_companies, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contributions_2016 = df_contributions_2016.merge(df_reps_2016, how='left', left_on='Full_Name', right_on='Representative')\n",
    "df_contributions_2018 = df_contributions_2018.merge(df_reps_2018, how='left', left_on='Full_Name', right_on='Representative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jlyp_Pt0lxcZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get list of all elected Candidates from 2015-2018\n",
    "reps = [df_reps_2016, df_reps_2018]\n",
    "df_reps = pd.concat(reps, sort=True)\n",
    "state_reps = list(df_reps['Representative'].unique())\n",
    "\n",
    "# Deallocate memory\n",
    "reps = []\n",
    "df_reps_2016 = []\n",
    "df_reps_2018 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine all contributions from 2015-2018\n",
    "contributions = [df_contributions_2016, df_contributions_2018]\n",
    "df_contributions = pd.concat(contributions, sort=True)\n",
    "\n",
    "# Deallocate memory\n",
    "contributions = []\n",
    "df_contributions_2016 = []\n",
    "df_contributions_2018 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsBMxplnlxce",
    "outputId": "adac16ce-a40d-435c-db7b-893e7066bb58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(894666, 22)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(state_reps))\n",
    "display(df_contributions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contribution_state_reps = df_contributions.loc[df_contributions.Full_Name.isin(state_reps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Creating new Donor_Name column that will allow easier analysis here\n",
    "# and moving forward\n",
    "\n",
    "import math\n",
    "\n",
    "def donor_name(first_name, last_name):\n",
    "    donor_name = ''\n",
    "    if (type(first_name) == str):\n",
    "        donor_name += first_name.upper().replace(\":-,.'&\", ' ') + ' '\n",
    "    if (type(last_name) == str):\n",
    "        donor_name += last_name.upper().replace(\":-,.'&\", ' ')\n",
    "    return donor_name\n",
    "\n",
    "df_contribution_state_reps['Donor_Name'] = df_contribution_state_reps[['First_Name', 'Last_Name']].apply(lambda x: donor_name(x[0], x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Regular Expression Search for each Industry\n",
    "\n",
    "# Law Enforcement\n",
    "law_enforcement_keywords = ['law enforcement', 'district attorney', 'prosecutor', 'detective', 'trooper', 'probation officer', 'sheriff', 'correction', 'prison', 'patrolm[ae]n', 'parole', 'court', 'trial', 'firefighter', 'fire fighter']\n",
    "law_enforcement_regex = ''\n",
    "\n",
    "for line in law_enforcement_keywords:\n",
    "    law_enforcement_regex += '(' + line +')|'\n",
    "\n",
    "law_enforcement_regex += '(police)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education\n",
    "education_keywords = ['teacher', 'professor', 'lecture', 'educator', 'university', 'school', 'college', 'tutor', 'tuition', 'academ(y|ic)']\n",
    "education_regex = ''\n",
    "\n",
    "for line in education_keywords:\n",
    "    education_regex += '(' + line +')|'\n",
    "\n",
    "education_regex += '(education)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Estate\n",
    "realestate_keywords = ['realtor', 'realty', 'housing', 'build', 'leasing', '[^(it)|^(software )|^(data )]developer', '[^(it )|^(software )|^(data )]architect', 'construction', 'lodging', 'propert(y|ies)', 'residential', 'contractor', 'pile drive']\n",
    "realestate_regex = ''\n",
    "\n",
    "for line in realestate_keywords:\n",
    "    realestate_regex += '(' + line +')|'\n",
    "\n",
    "# for row in df_real_estate:\n",
    "#     row.lower().replace(\":-,.'&\", ' ')\n",
    "\n",
    "realestate_regex += '(real estate)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Healthcare\n",
    "# Note - 'ophthalm', 'optometr', 'urolog', 'chiropract', 'psychiatr', 'psycholog' are added to match root words of medical specializations\n",
    "healthcare_keywords = ['health care', 'health', 'medical', 'hospital', 'nurse', 'rehab', 'nursing', 'clinic', 'doctor', 'psycholog', 'surgeon', 'dental', 'dentist', 'phys[i]+cian', 'op[h]+thalm', 'urolog', 'pharmac', 'optometr', 'eye care', 'eye center', 'chiropract', 'psychiatr', 'podiatr', '\\wem[ts]\\w', 'ambul[ae]nce', 'emergency']\n",
    "# , '\\wrn\\w'\n",
    "healthcare_regex = ''\n",
    "\n",
    "for line in healthcare_keywords:\n",
    "    healthcare_regex += '(' + line +')|'\n",
    "\n",
    "healthcare_regex += '(healthcare)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioTech / Pharma\n",
    "biotech_keywords = ['genetech', 'bioscience', 'pharma']\n",
    "biotech_regex = ''\n",
    "\n",
    "for line in biotech_keywords:\n",
    "    biotech_regex += '(' + line +')|'\n",
    "\n",
    "biotech_regex += '(bio science)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "energy_keywords = ['eversource', 'sunpower', 'grid', 'wind', 'solar']\n",
    "energy_regex = ''\n",
    "\n",
    "for line in energy_keywords:\n",
    "    energy_regex += '(' + line +')|'\n",
    "\n",
    "energy_regex += '(energy)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transport\n",
    "transport_keywords = ['(?!pile )drive', 'teamster', 'truck', 'motor', 'ferry', 'cruise', 'air[ ]*port', 'sea[ ]*port']\n",
    "transport_regex = ''\n",
    "\n",
    "for line in transport_keywords:\n",
    "    transport_regex += '(' + line +')|'\n",
    "\n",
    "transport_regex += '(transport)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirees\n",
    "retiree_keywords = ['retire']\n",
    "retiree_regex = ''\n",
    "\n",
    "for line in retiree_keywords:\n",
    "    retiree_regex += '(' + line +')|'\n",
    "\n",
    "retiree_regex += '(retire)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-employed\n",
    "self_employed_keywords = ['^self$', 'owner']\n",
    "self_employed_regex = ''\n",
    "\n",
    "for line in self_employed_keywords:\n",
    "    self_employed_regex += '(' + line +')|'\n",
    "\n",
    "self_employed_regex += '(self employ)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unemployed\n",
    "unemployed_keywords = ['not employ', 'at home', 'none', '^0$', 'home[ ]*maker', 'house[ ]*wife']\n",
    "unemployed_regex = ''\n",
    "\n",
    "for line in unemployed_keywords:\n",
    "    unemployed_regex += '(' + line +')|'\n",
    "\n",
    "unemployed_regex += '(unemploy)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Government\n",
    "government_keywords = ['commonwealth of ma', 'reimbursement']\n",
    "government_regex = ''\n",
    "\n",
    "for line in government_keywords:\n",
    "    government_regex += '(' + line +')|'\n",
    "\n",
    "government_regex += '(government)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_industry(donor_name, occupation, employer):\n",
    "    text = str(donor_name) + ' ' + str(occupation) + ' ' + str(employer)\n",
    "    text = text.lower().replace(\":-,.'&\", ' ')\n",
    "#     display(text)\n",
    "    \n",
    "    if(re.search(law_enforcement_regex, text)):\n",
    "        return 'Law Enforcement'\n",
    "    if (re.search(education_regex, text)):\n",
    "        return 'Education'\n",
    "    if (re.search(realestate_regex, text)):\n",
    "        return 'Real Estate'\n",
    "    if (re.search(healthcare_regex, text)):\n",
    "        return 'Healthcare'\n",
    "    if (re.search(biotech_regex, text)):\n",
    "        return 'Biotech/Pharma'\n",
    "    if (re.search(energy_regex, text)):\n",
    "        return 'Utilities'\n",
    "    if (re.search(retiree_regex, text)):\n",
    "        return 'Retired'\n",
    "    if (re.search(self_employed_regex, text)):\n",
    "        return 'Self-Employed'\n",
    "    if (re.search(unemployed_regex, text)):\n",
    "        return 'Unemployed'\n",
    "    if(re.search(government_regex, text)):\n",
    "        return 'Government'\n",
    "    if(re.search(transport_regex, text)):\n",
    "        return 'Transportation'\n",
    "    \n",
    "    for row in df_real_estate['Company']:\n",
    "        if (type(employer)==str):\n",
    "            found = fuzzy_compare(employer, row)\n",
    "            if (found):\n",
    "                return 'Real Estate'\n",
    "        if (type(donor_name)==str):\n",
    "            found = fuzzy_compare(donor_name, row)\n",
    "            if (found):\n",
    "                return 'Real Estate'\n",
    "    \n",
    "    if(type(occupation)==float and type(employer)==float):\n",
    "        if(np.isnan(occupation) and np.isnan(employer)):\n",
    "            return 'Unreported'\n",
    "    \n",
    "    # Case no match found\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAC keywords\n",
    "PAC_keywords = ['\\Wpac\\W', 'pol action', 'political action', 'committee', 'action']\n",
    "PAC_regex = ''\n",
    "\n",
    "for line in PAC_keywords:\n",
    "    PAC_regex += '(' + line +')|'\n",
    "\n",
    "PAC_regex += '(real estate)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union Keywords\n",
    "union_keywords = ['\\Wunion\\W', 'association']\n",
    "union_regex = ''\n",
    "\n",
    "for line in union_keywords:\n",
    "    union_regex += '(' + line +')|'\n",
    "\n",
    "union_regex += '(union pac)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lobbyist Keywords\n",
    "lobbyist_keywords = ['lobbyist']\n",
    "lobbyist_regex = ''\n",
    "\n",
    "for line in lobbyist_keywords:\n",
    "    lobbyist_regex += '(' + line +')|'\n",
    "\n",
    "lobbyist_regex += '(lobby)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate\n",
    "candidate_keywords = []\n",
    "candidate_regex = ''\n",
    "\n",
    "for line in candidate_keywords:\n",
    "    candidate_regex += '(' + line +')|'\n",
    "\n",
    "candidate_regex += '(reimbursement)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fuzzy_compare(str1, str2):\n",
    "    str1 = str(str1)\n",
    "    str2 = str(str2)\n",
    "    ratio = fuzz.ratio(str1.lower().replace(\":-,.'&\", ' '), str2.lower().replace(\":-,.'&\", ' '))\n",
    "    if (ratio > 85):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_state_reps = pd.DataFrame(state_reps, columns = ['Representative'])\n",
    "# display(df_state_reps['Representative'].head())\n",
    "\n",
    "def find_PAC(donor_name, candidate_name): \n",
    "    text = ' ' + str(donor_name) + ' '\n",
    "    text = text.lower().replace(\":-,.'&\", ' ')\n",
    "#     display(text)\n",
    "    # Note - Union checking must come before PAC because of \"union pac\"\n",
    "    if(re.search(union_regex, text)):\n",
    "        return 'Union'\n",
    "    if(re.search(PAC_regex, text)):\n",
    "        return 'PAC'\n",
    "    if(re.search(candidate_regex, text)):\n",
    "        return 'Candidate'\n",
    "    \n",
    "    candidateFound = fuzzy_compare(donor_name, candidate_name)\n",
    "    if (candidateFound):\n",
    "        return 'Candidate'\n",
    "    \n",
    "    # Case no match found\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_contribution_state_reps['Industry'] = df_contribution_state_reps[['Donor_Name', 'Occupation', 'Employer']].apply(lambda x: find_industry(x[0], x[1], x[2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_contribution_state_reps['PAC'] = df_contribution_state_reps[['Donor_Name', 'Full_Name']].apply(lambda x: find_PAC(x[0], x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Remove special charecters, numbers\n",
    "    Return lower case alphabet charecters only\n",
    "    '''\n",
    "    text = str(text).upper()\n",
    "    text = re.sub('[^A-Za-z]+', '', text)\n",
    "    return text\n",
    "\n",
    "def takeoff_par(name):\n",
    "    name = str(name)\n",
    "    head, sep, tail = name.partition('(')\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of Lobbyist names\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_lobby_2016 = pd.read_csv('data/lobbyist(2015-2016).csv')\n",
    "df_lobby_2018 = pd.read_csv('data/lobbyist(2017-2018).csv')\n",
    "\n",
    "lobby_list = df_lobby_2016.append(df_lobby_2018)['Name'].unique()\n",
    "donor_list = df_contribution_state_reps['Donor_Name'].unique()\n",
    "\n",
    "lobby_list = [takeoff_par(x) for x in lobby_list]\n",
    "lobby_list_clean = [clean_text(x) for x in lobby_list]\n",
    "donor_list_clean = [clean_text(x) for x in donor_list]\n",
    "\n",
    "match = []\n",
    "donor_list_clean = np.array(donor_list_clean)\n",
    "lobby_list_clean = np.array(lobby_list_clean)\n",
    "for donor in donor_list_clean:\n",
    "    for lobby in lobby_list_clean:\n",
    "        if fuzz.ratio(donor, lobby) >= 85:\n",
    "            match.append(donor)\n",
    "            \n",
    "match_un = np.array(match.copy())\n",
    "match_set = set(match.copy())\n",
    "\n",
    "df_match_set = pd.DataFrame(match_set, columns=['Lobbyist'])\n",
    "df_match_set.to_csv(os.getcwd() +  '/data/lobbyist_names.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_contribution_state_reps['Donor_clean'] = df_contribution_state_reps['Donor_Name'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_match_set = pd.read_csv(os.getcwd() +  '/data/lobbyist_names.csv')\n",
    "\n",
    "def lobby_search(name):\n",
    "    return name in df_match_set['Lobbyist'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_contribution_state_reps['Lobbyist'] = df_contribution_state_reps['Donor_clean'].apply(lobby_search)\n",
    "# df_contribution_state_reps.drop(columns=['Donor_clean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contribution_state_reps.to_csv(os.getcwd() +  '/data/contribution_processed.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
